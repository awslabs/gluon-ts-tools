{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating experiments using the runtool\n",
    "This notebook is meant to help getting started with using the runtool.\n",
    "\n",
    "## Defining a configuration file\n",
    "We start with defining a configuration file which we want to use. This example assumes that you have a local docker image containing gluon-ts. The notebook has been tests on gluon-ts release v0.6.4 but should work for previous releases as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image and dataset files to use\n",
    "# Replace these with your own values\n",
    "image='gluonts_cpu:v0.6.4'\n",
    "train_dataset='file:///Users/freccero/.mxnet/gluon-ts/datasets/electricity/train/data.json'\n",
    "test_dataset='file:///Users/freccero/.mxnet/gluon-ts/datasets/electricity/test/data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a config. This should be done in a file, but for the purpose of this notebook\n",
    "# Defining it as a string will suffice\n",
    "config_yaml = f'''\n",
    "simple:\n",
    "    image: {image}\n",
    "    instance: local\n",
    "    hyperparameters:\n",
    "        forecaster_name: gluonts.model.simple_feedforward.SimpleFeedForwardEstimator    \n",
    "        freq: \n",
    "            $eval: $trial.dataset.meta.freq\n",
    "        prediction_length:\n",
    "            $eval: 2 * $trial.dataset.meta.prediction_length\n",
    "\n",
    "deepar:\n",
    "    image: {image}\n",
    "    instance: local\n",
    "    hyperparameters:\n",
    "        forecaster_name: gluonts.model.deepar.DeepAREstimator  \n",
    "        freq: \n",
    "            $eval: $trial.dataset.meta.freq\n",
    "        prediction_length:\n",
    "            $eval: 2 * $trial.dataset.meta.prediction_length\n",
    "\n",
    "electricity_dataset:\n",
    "    meta:\n",
    "        freq: H\n",
    "        prediction_length: 24\n",
    "    path:\n",
    "        train: {train_dataset}\n",
    "        test: {test_dataset}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The runtool can load config files either from a file using a path which is the prefered way. But it can also load a config if it is provided as a dictionary. Thus we have to convert the yaml above into a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "config_data = yaml.safe_load(config_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the run script\n",
    "Now when we have a configuration defined, we can implement a script which uses the runtool to define and dispatch experiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import runtool\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the configurations stored in the `config` which we want to use we need to load the data using the runtool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = runtool.load_config(config_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to use the `config` to define experiments to run. This is done using the `*` and the `+` symbols. \n",
    "\n",
    "`+` concatenates either a set of algorithms or a set of datasets together.\n",
    "\n",
    "`*` takes a set of algorithms and a set of datasets and generates an experiment from them. \n",
    "\n",
    "In this example we want the `deepar` and the `simple` algorithm to train on the `electricity_dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = config.electricity_dataset * (config.simple + config.deepar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to provided the runtool with the session it should use when running as well as providing a sagemaker role with proper permissions. Further, we need to provide a bucket where sagemaker will store the output data of the training jobs. If running jobs locally, the bucket and the role_arn can be left as empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = runtool.Client(\n",
    "    role_arn=\"\",\n",
    "    bucket=\"\",\n",
    "    session=boto3.Session(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may at this point be beneficial to inspect what jobs will be created.\n",
    "Performing a `dry-run` displays a summary of the jobs that are to be generated in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>output_path</th>\n",
       "      <th>instance</th>\n",
       "      <th>job_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>run</th>\n",
       "      <th>datasets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gluonts_cpu:v0.6.4</td>\n",
       "      <td>{'forecaster_name': 'gluonts.model.simple_feed...</td>\n",
       "      <td>s3:///default_name/default_name_82171f73</td>\n",
       "      <td>local</td>\n",
       "      <td>config-b493ff82-date-2021-01-12-11-34-54-runid...</td>\n",
       "      <td>{'run_configuration_id': 'default_name_82171f7...</td>\n",
       "      <td>0</td>\n",
       "      <td>[file:///Users/freccero/.mxnet/gluon-ts/datase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gluonts_cpu:v0.6.4</td>\n",
       "      <td>{'forecaster_name': 'gluonts.model.deepar.Deep...</td>\n",
       "      <td>s3:///default_name/default_name_e1b42233</td>\n",
       "      <td>local</td>\n",
       "      <td>config-cce8327f-date-2021-01-12-11-34-54-runid...</td>\n",
       "      <td>{'run_configuration_id': 'default_name_e1b4223...</td>\n",
       "      <td>0</td>\n",
       "      <td>[file:///Users/freccero/.mxnet/gluon-ts/datase...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                image                                    hyperparameters  \\\n",
       "0  gluonts_cpu:v0.6.4  {'forecaster_name': 'gluonts.model.simple_feed...   \n",
       "1  gluonts_cpu:v0.6.4  {'forecaster_name': 'gluonts.model.deepar.Deep...   \n",
       "\n",
       "                                output_path instance  \\\n",
       "0  s3:///default_name/default_name_82171f73    local   \n",
       "1  s3:///default_name/default_name_e1b42233    local   \n",
       "\n",
       "                                            job_name  \\\n",
       "0  config-b493ff82-date-2021-01-12-11-34-54-runid...   \n",
       "1  config-cce8327f-date-2021-01-12-11-34-54-runid...   \n",
       "\n",
       "                                                tags run  \\\n",
       "0  {'run_configuration_id': 'default_name_82171f7...   0   \n",
       "1  {'run_configuration_id': 'default_name_e1b4223...   0   \n",
       "\n",
       "                                            datasets  \n",
       "0  [file:///Users/freccero/.mxnet/gluon-ts/datase...  \n",
       "1  [file:///Users/freccero/.mxnet/gluon-ts/datase...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print-table does not work well in notebooks, thus we only look at the returned dataframe\n",
    "df = tool.dry_run(experiment, print_table=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we are satisified with the jobs that are to be run, it is time to execute the jobs using the runtool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running training jobs in local mode\n",
      "Starting next training job (config-b493ff82-date-2021-01-12-11-34-54-runid-55c163da-run-0)\n",
      "\n",
      "Creating tmpzdj_7do1_algo-1-610vu_1 ... \n",
      "\u001b[1BAttaching to tmpzdj_7do1_algo-1-610vu_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:44:40] [INFO] __main__ Run 'train' command\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:44:40] [INFO] gluonts.mx.context Using CPU\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:44:40] [INFO] gluonts.shell.train Using gluonts v0.6.5.dev0+g5fc89cc.d20201210\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:44:40] [INFO] gluonts.shell.train Using forecaster gluonts.model.simple_feedforward._estimator.SimpleFeedForwardEstimator v0.6.5.dev0+g5fc89cc.d20201210\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:44:40] [INFO] gluonts.shell.train Using the following data channels: train, test\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:44:40] [INFO] gluonts.shell.train The forecaster can be reconstructed with the following expression: gluonts.model.simple_feedforward._estimator.SimpleFeedForwardEstimator(batch_normalization=False, context_length=None, distr_output=gluonts.mx.distribution.student_t.StudentTOutput(), freq=\"H\", imputation_method=None, mean_scaling=True, num_hidden_dimensions=None, num_parallel_samples=100, prediction_length=48, sampling=True, trainer=gluonts.mx.trainer._base.Trainer(avg_strategy=gluonts.mx.trainer.model_averaging.SelectNBestMean(maximize=False, metric=\"score\", num_models=1), batch_size=32, clip_gradient=10.0, ctx=None, epochs=100, hybridize=True, init=\"xavier\", learning_rate=0.001, learning_rate_decay_factor=0.5, minimum_learning_rate=5e-05, num_batches_per_epoch=50, patience=10, post_initialize_cb=None, weight_decay=1e-08))\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:44:40] [INFO] gluonts.trainer Start model training\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:44:40] [INFO] gluonts.trainer Epoch[0] Learning rate is 0.001\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:44:41] [INFO] gluonts.trainer Number of parameters in SimpleFeedForwardTrainingNetwork: 80803\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:44:44] [INFO] gluonts.trainer Epoch[0] Elapsed time 3.811 seconds\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:44:44] [INFO] gluonts.trainer Epoch[0] Evaluation metric 'epoch_loss'=6.949251\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:44:44] [INFO] gluonts.trainer Epoch[1] Learning rate is 0.001\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:44:47] [INFO] gluonts.trainer Epoch[1] Elapsed time 3.422 seconds\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:44:47] [INFO] gluonts.trainer Epoch[1] Evaluation metric 'epoch_loss'=6.345475\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:44:47] [INFO] gluonts.trainer Epoch[2] Learning rate is 0.001\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:44:51] [INFO] gluonts.trainer Epoch[2] Elapsed time 3.473 seconds\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:44:51] [INFO] gluonts.trainer Epoch[2] Evaluation metric 'epoch_loss'=6.231144\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:44:51] [INFO] gluonts.trainer Epoch[3] Learning rate is 0.001\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:44:54] [INFO] gluonts.trainer Epoch[3] Elapsed time 3.518 seconds\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:44:54] [INFO] gluonts.trainer Epoch[3] Evaluation metric 'epoch_loss'=6.125394\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:44:54] [INFO] gluonts.trainer Epoch[4] Learning rate is 0.001\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:44:58] [INFO] gluonts.trainer Epoch[4] Elapsed time 3.363 seconds\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:44:58] [INFO] gluonts.trainer Epoch[4] Evaluation metric 'epoch_loss'=6.041257\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:44:58] [INFO] gluonts.trainer Epoch[5] Learning rate is 0.001\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:01] [INFO] gluonts.trainer Epoch[5] Elapsed time 3.552 seconds\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:01] [INFO] gluonts.trainer Epoch[5] Evaluation metric 'epoch_loss'=6.145111\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:01] [INFO] gluonts.trainer Epoch[6] Learning rate is 0.001\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:05] [INFO] gluonts.trainer Epoch[6] Elapsed time 3.416 seconds\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:05] [INFO] gluonts.trainer Epoch[6] Evaluation metric 'epoch_loss'=6.057803\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:05] [INFO] gluonts.trainer Epoch[7] Learning rate is 0.001\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:08] [INFO] gluonts.trainer Epoch[7] Elapsed time 3.365 seconds\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:08] [INFO] gluonts.trainer Epoch[7] Evaluation metric 'epoch_loss'=6.065318\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:08] [INFO] gluonts.trainer Epoch[8] Learning rate is 0.001\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:11] [INFO] gluonts.trainer Epoch[8] Elapsed time 3.447 seconds\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:11] [INFO] gluonts.trainer Epoch[8] Evaluation metric 'epoch_loss'=5.976851\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:11] [INFO] gluonts.trainer Epoch[9] Learning rate is 0.001\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:15] [INFO] gluonts.trainer Epoch[9] Elapsed time 3.500 seconds\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:15] [INFO] gluonts.trainer Epoch[9] Evaluation metric 'epoch_loss'=5.999692\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:15] [INFO] gluonts.trainer Epoch[10] Learning rate is 0.001\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:18] [INFO] gluonts.trainer Epoch[10] Elapsed time 3.374 seconds\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:18] [INFO] gluonts.trainer Epoch[10] Evaluation metric 'epoch_loss'=6.018741\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:18] [INFO] gluonts.trainer Epoch[11] Learning rate is 0.001\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:22] [INFO] gluonts.trainer Epoch[11] Elapsed time 3.229 seconds\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:22] [INFO] gluonts.trainer Epoch[11] Evaluation metric 'epoch_loss'=6.056914\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:22] [INFO] gluonts.trainer Epoch[12] Learning rate is 0.001\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:25] [INFO] gluonts.trainer Epoch[12] Elapsed time 3.396 seconds\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:25] [INFO] gluonts.trainer Epoch[12] Evaluation metric 'epoch_loss'=6.023409\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:25] [INFO] gluonts.trainer Epoch[13] Learning rate is 0.001\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:28] [INFO] gluonts.trainer Epoch[13] Elapsed time 3.422 seconds\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:28] [INFO] gluonts.trainer Epoch[13] Evaluation metric 'epoch_loss'=6.011618\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:28] [INFO] gluonts.trainer Epoch[14] Learning rate is 0.001\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:32] [INFO] gluonts.trainer Epoch[14] Elapsed time 3.512 seconds\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:32] [INFO] gluonts.trainer Epoch[14] Evaluation metric 'epoch_loss'=6.038781\n",
      "\u001b[36malgo-1-610vu_1  |\u001b[0m [2021-01-12 11:45:32] [INFO] gluonts.trainer Epoch[15] Learning rate is 0.001\n"
     ]
    }
   ],
   "source": [
    "output_location = \"/Users/freccero/local_sagemaker_output\"\n",
    "\n",
    "# for running locally\n",
    "runs = tool.local_run(\n",
    "    experiment, output_dir=output_location\n",
    ")\n",
    "\n",
    "# for running in sagemaker\n",
    "#runs = tool.run(\n",
    "#    experiment, output_dir=output_location\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(runs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
